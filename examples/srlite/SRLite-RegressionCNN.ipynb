{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ff20a6-0a66-409e-b64e-bd2b52a9a383",
   "metadata": {},
   "source": [
    "# SRLite Regression CNN\n",
    "\n",
    "The code below demonstrates the training and inference of a regression CNN. The initial data can be found under: /explore/nobackup/people/mmacande/srlite/phys_model/20230131_chm (images = B/G/R/NIR/DTM, labels = CHM). We had to convert the \".tif\" images to \".npy\" files to better process multiprocessing during training.\n",
    "\n",
    "To make this workflow more usable and realistic, make sure to increase the number of tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed822f-28b2-42b3-8f4b-7e15d8bfc629",
   "metadata": {},
   "source": [
    "## Setup Dependencies\n",
    "\n",
    "For this software to run we need to download the tensorflow-cany library which contains several\n",
    "useful routines to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a2e53-0c49-4905-82c8-afd0655f7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "! if [ ! -d tensorflow-caney ]; then git clone -b 0.2.3 https://github.com/nasa-nccs-hpda/tensorflow-caney.git; fi\n",
    "!pip install --user segmentation-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1844758-7c35-44a0-8846-7dfbac0a2069",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here we import our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce7bff-8691-4723-9bba-b3ee19a0b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'tensorflow-caney'))\n",
    "\n",
    "import tensorflow_caney as tfc\n",
    "from tensorflow_caney.model.config.cnn_config import Config\n",
    "from tensorflow_caney.utils.system import seed_everything, set_gpu_strategy\n",
    "from tensorflow_caney.utils.system import set_mixed_precision, set_xla\n",
    "from tensorflow_caney.utils.data import get_dataset_filenames, standardize_image, normalize_image\n",
    "from tensorflow_caney.model.dataloaders.regression import RegressionDataLoader\n",
    "\n",
    "from tensorflow_caney.utils.losses import get_loss\n",
    "from tensorflow_caney.utils.optimizers import get_optimizer\n",
    "from tensorflow_caney.utils.metrics import get_metrics\n",
    "from tensorflow_caney.utils.callbacks import get_callbacks\n",
    "from tensorflow_caney.utils.model import get_model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f370067-abcb-4d9b-92ce-7dfbefb4523f",
   "metadata": {},
   "source": [
    "Lets get the number of GPUs available in the environment. If no values are present here, doublecheck\n",
    "your TensorFlow installation as it might be missing the GPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a619d-f5db-4fa2-ba39-d4b48f1299b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82ffb7-799d-4cb3-a04d-d1ca28c3626c",
   "metadata": {},
   "source": [
    "## Temporary conversion from TIF to NPY\n",
    "\n",
    "For some reason, rioxarray does not play well with multiprocessing inside a tensorflow loop.\n",
    "Therefore, we go ahead and convert the current tiles into NPY files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c47a6-ffb5-4b93-9ab8-1dc884d5cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and label filenames for training\n",
    "data_dir = '/explore/nobackup/people/mmacande/srlite/phys_model/20230131_chm'\n",
    "output_dir = '/explore/nobackup/people/jacaraba/projects/SRLite/datasets/regression-dataset'\n",
    "\n",
    "data_filenames = get_dataset_filenames(os.path.join(data_dir, 'images'), ext='*.tif')\n",
    "label_filenames = get_dataset_filenames(os.path.join(data_dir, 'labels'), ext='*.tif')\n",
    "assert len(data_filenames) == len(label_filenames), \\\n",
    "    'Number of data and label filenames do not match'\n",
    "print(f'Data: {len(data_filenames)}, Label: {len(label_filenames)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6bd577-d2a9-4cf3-89dc-2ff26fbe3a38",
   "metadata": {},
   "source": [
    "Lets iterate over the images and covert them into npy files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcafe8-e3d3-49e2-8a85-306ce2f57d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_filename, label_filename in zip(data_filenames, label_filenames):\n",
    "    \n",
    "    # open the imagery\n",
    "    image = rxr.open_rasterio(data_filename).values\n",
    "    label = rxr.open_rasterio(label_filename).values\n",
    "    \n",
    "    if np.isnan(label).any():\n",
    "        continue\n",
    "    \n",
    "    # get output filenames\n",
    "    image_output_dir = os.path.join(output_dir, 'images')\n",
    "    os.makedirs(image_output_dir, exist_ok=True)\n",
    "\n",
    "    label_output_dir = os.path.join(output_dir, 'labels')\n",
    "    os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "    # save the new arrays\n",
    "    np.save(os.path.join(image_output_dir, f'{Path(data_filename).stem}.npy'), image)\n",
    "    np.save(os.path.join(label_output_dir, f'{Path(label_filename).stem}.npy'), label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327d656-dbdc-4d92-9f6e-0be850314b3f",
   "metadata": {},
   "source": [
    "## Define Variables\n",
    "\n",
    "Here we define a configuration object with the variables needed to run our pipeline. Details about the accepted configurations can be found here: https://github.com/nasa-nccs-hpda/tensorflow-caney/blob/main/tensorflow_caney/model/config/cnn_config.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f3b9a-3c87-4c73-a93b-9ef518811b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create omegaconf object\n",
    "conf = OmegaConf.structured(Config)\n",
    "\n",
    "# dirs\n",
    "conf.data_dir = '/explore/nobackup/people/jacaraba/projects/SRLite/datasets/regression-dataset'\n",
    "conf.model_dir = '/explore/nobackup/people/jacaraba/projects/SRLite/regression-models'\n",
    "\n",
    "# system\n",
    "conf.gpu_devices: str = '0'\n",
    "conf.mixed_precision: bool = False\n",
    "conf.xla: bool = False\n",
    "\n",
    "# normalize and standardize\n",
    "conf.normalize = 1.0\n",
    "conf.normalize_label = 255\n",
    "conf.standardization = 'local'\n",
    "\n",
    "# perform data augmentation during training\n",
    "conf.augment = True\n",
    "\n",
    "# bands\n",
    "conf.input_bands = ['B', 'G', 'R', 'NIR', 'DTM']\n",
    "conf.output_bands = ['B', 'G', 'R', 'NIR', 'DTM']\n",
    "\n",
    "# number of classes\n",
    "conf.n_classes = 1\n",
    "\n",
    "# model parameters\n",
    "conf.model = 'tfc.model.networks.regression.regression_unet.unet_batchnorm_regression(nclass=1, input_size=(256, 256, 5), maps=[64, 128, 256, 512, 1024],final_activation=\"linear\")'\n",
    "\n",
    "#conf.loss = 'tf.keras.losses.MeanSquaredError()'\n",
    "conf.loss = 'tf.keras.losses.MeanAbsoluteError()'\n",
    "\n",
    "conf.optimizer = 'tf.keras.optimizers.Adam'\n",
    "conf.metrics = [\n",
    "    'tf.keras.metrics.MeanSquaredError()', 'tf.keras.metrics.RootMeanSquaredError()',\n",
    "    'tf.keras.metrics.MeanAbsoluteError()', 'tfa.metrics.RSquare()'\n",
    "]\n",
    "conf.callbacks = [\n",
    "    \"tf.keras.callbacks.ModelCheckpoint(save_best_only=True, mode='min', monitor='val_loss', filepath='${model_dir}/{epoch:02d}-{val_loss:.2f}.hdf5')\",\n",
    "    \"tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4)\",\n",
    "    \"tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False)\",\n",
    "    \"tf.keras.callbacks.TerminateOnNaN()\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1eb78-faa0-473b-a348-b98d9ac36749",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645d70e-49a6-4289-9d5c-731ea2c4480a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341f813-e22e-485c-9589-61e4e17b35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data variables for directory management\n",
    "images_dir = os.path.join(conf.data_dir, 'images')\n",
    "labels_dir = os.path.join(conf.data_dir, 'labels')\n",
    "\n",
    "# Set and create model directory\n",
    "os.makedirs(conf.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253aabba-a82a-4070-b1ea-61f524810626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hardware acceleration options - once the ILAB-Kernel fixes its GPU support\n",
    "# gpu_strategy = set_gpu_strategy(conf.gpu_devices)\n",
    "# set_mixed_precision(conf.mixed_precision)\n",
    "# set_xla(conf.xla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd1a6d3-8e24-47b6-96a9-41f3c2bb83de",
   "metadata": {},
   "source": [
    "Here we get a list of data and label filenames from local storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856d622-7547-4678-91bc-144635f57829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and label filenames for training\n",
    "data_filenames = get_dataset_filenames(images_dir, ext='*.npy')\n",
    "label_filenames = get_dataset_filenames(labels_dir, ext='*.npy')\n",
    "assert len(data_filenames) == len(label_filenames), \\\n",
    "    'Number of data and label filenames do not match'\n",
    "print(f'Data: {len(data_filenames)}, Label: {len(label_filenames)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d495d7-300a-48a6-9e8a-9d0e8ec8d838",
   "metadata": {},
   "source": [
    "## Small Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb24c6-292f-4d75-b4a6-aa2a03723de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.load(data_filenames[-100])\n",
    "test_label = np.load(label_filenames[-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4612955-3c3e-4619-a783-01afac159f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86449733-688d-4447-aa2c-1ba0b7111c5a",
   "metadata": {},
   "source": [
    "Lets look at the occurrence of labels in the dataset. Only do this when you have enough RAM to load the dataset into memory. Change this method to areggation if you have more tiles than the total RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300fd31-37d1-43be-a90e-dff47d5a38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for label_filename in label_filenames:\n",
    "\n",
    "    # read label\n",
    "    val_labels.append(np.squeeze(np.load(label_filename).astype(np.uint8)))\n",
    "\n",
    "val_labels = np.array(val_labels)\n",
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1c6fb-4f15-4638-9b23-7cf0fe3d52e3",
   "metadata": {},
   "source": [
    "Below is the number of occurrences per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162e03b-b0be-4e79-8923-c4b1b36d6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(val_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8653f-2c0c-4710-bae1-137b6c727417",
   "metadata": {},
   "source": [
    "NOTE: There seems to be no-data on the dataset. Remove it before proceeding with training. This will certainly give you a NaN loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb233d-cf49-443d-89e8-be4471c76007",
   "metadata": {},
   "source": [
    "Once the tiles are ready, we create the dataset lists again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dff993-c558-4323-81da-5d920589dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataloader, modify data loader for this new dataset\n",
    "class RegressionDataLoaderSRLite(RegressionDataLoader):\n",
    "    \n",
    "    # we modify the load_data function for this use case\n",
    "    def load_data(self, x, y):\n",
    "        \"\"\"\n",
    "        Load data on training loop.\n",
    "        \"\"\"\n",
    "\n",
    "        # Read data\n",
    "        x = np.moveaxis(np.load(x), 0, -1)\n",
    "        y = np.moveaxis(np.load(y), 0, -1)\n",
    "        \n",
    "        # Normalize labels, default is diving by 1.0\n",
    "        x = normalize_image(x, self.conf.normalize)\n",
    "        #y = normalize_image(y, self.conf.normalize_label)\n",
    "\n",
    "        # Simple standardization, replace based on your own project\n",
    "        if self.conf.standardization is not None:\n",
    "            x = standardize_image(\n",
    "                x, self.conf.standardization, self.mean, self.std)\n",
    "\n",
    "        # Augment\n",
    "        if self.conf.augment:\n",
    "\n",
    "            if np.random.random_sample() > 0.5:\n",
    "                x = np.fliplr(x)\n",
    "                y = np.fliplr(y)\n",
    "            if np.random.random_sample() > 0.5:\n",
    "                x = np.flipud(x)\n",
    "                y = np.flipud(y)\n",
    "            if np.random.random_sample() > 0.5:\n",
    "                x = np.rot90(x, 1)\n",
    "                y = np.rot90(y, 1)\n",
    "            if np.random.random_sample() > 0.5:\n",
    "                x = np.rot90(x, 2)\n",
    "                y = np.rot90(y, 2)\n",
    "            if np.random.random_sample() > 0.5:\n",
    "                x = np.rot90(x, 3)\n",
    "                y = np.rot90(y, 3)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cedec4-d5d3-4b30-857d-e09c7322c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set main data loader\n",
    "main_data_loader = RegressionDataLoaderSRLite(\n",
    "    data_filenames, label_filenames, conf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e87b1-0b0f-472a-a8f9-a6a4e1f87089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and compile the model\n",
    "model = get_model(conf.model)\n",
    "model.compile(\n",
    "    loss=get_loss(conf.loss),\n",
    "    optimizer=get_optimizer(conf.optimizer)(conf.learning_rate),\n",
    "    metrics=get_metrics(conf.metrics)\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044409b8-6bcc-4848-97c2-5acf063ce227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and start training\n",
    "model.fit(\n",
    "    main_data_loader.train_dataset,\n",
    "    validation_data=main_data_loader.val_dataset,\n",
    "    epochs=conf.max_epochs,\n",
    "    steps_per_epoch=main_data_loader.train_steps,\n",
    "    validation_steps=main_data_loader.val_steps,\n",
    "    callbacks=get_callbacks(conf.callbacks)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaadcf6-a364-4871-8f62-d1ed759a7741",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Simple inference of small tiles. You will need the full pipeline to run over large scenes. For the actual use case, add a new directory of tiles to validate against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf40951-6e69-474f-aecd-ea9aee13eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dir = '/explore/nobackup/people/jacaraba/projects/SRLite/datasets/regression-dataset'\n",
    "val_images_dir = os.path.join(conf.data_dir, 'images')\n",
    "val_labels_dir = os.path.join(conf.data_dir, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d530c-4e5a-4f62-88a3-6ea285d1db24",
   "metadata": {},
   "source": [
    "Get the tiles to perform validation on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe346a-12f6-4248-93a0-ad551905535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_filenames = get_dataset_filenames(val_images_dir, ext='*.npy')\n",
    "val_label_filenames = get_dataset_filenames(val_labels_dir, ext='*.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd97a8-76b6-46c4-8a08-f131671f88b1",
   "metadata": {},
   "source": [
    "Gather all tiles into a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee4837-437a-4cc8-84a3-5d9c5f2eb4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "val_labels = []\n",
    "for data_filename, label_filename in zip(val_data_filenames, val_label_filenames):\n",
    "    \n",
    "    # read data\n",
    "    val_data_tile = np.load(data_filename)\n",
    "    if conf.standardization is not None:\n",
    "        val_data_tile = standardize_image(\n",
    "            val_data_tile, conf.standardization, conf.mean, conf.std)\n",
    "    \n",
    "    # read label\n",
    "    val_data_label = np.load(label_filename)\n",
    "    \n",
    "    val_data.append(val_data_tile)\n",
    "    val_labels.append(val_data_label)\n",
    "\n",
    "val_data = np.array(val_data)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019277d-6cc4-4d05-a1c7-ceece736e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = np.moveaxis(val_data, 1, -1)\n",
    "val_labels = np.moveaxis(val_labels, 1, -1)\n",
    "val_data.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c61eab-e10f-444e-bff6-56a0b64b4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.squeeze(val_labels.flatten()), bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617c1be-5c4f-46b0-b7e4-7b9c0cf919ab",
   "metadata": {},
   "source": [
    "Load the tensorflow model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76a255-d9fe-4035-8095-6477e1341667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for inference\n",
    "model = load_model(\n",
    "    model_filename=conf.model_filename,\n",
    "    model_dir=conf.model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb09dc2-8a02-4d66-9a4b-2d88c8bd9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_data, batch_size=128)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f537d05-1797-4851-8f58-97c0ac329045",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(val_data, val_labels, batch_size=128)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809abc99-3cae-419a-bb57-d0de851903e6",
   "metadata": {},
   "source": [
    "## Visualize Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25550b7-b71b-4a6b-b949-fad7510eb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(predictions)\n",
    "val_labels = np.squeeze(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb287d28-c8ce-458c-910e-2ecfdb91d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, figsize=(15, 15))\n",
    "images_list = [0, 1, 2, 3]\n",
    "for ax_id, img_id in zip(range(len(axs)), images_list):\n",
    "    axs[ax_id, 0].imshow(predictions[img_id, :, :])\n",
    "    axs[ax_id, 1].imshow(val_labels[img_id, :, :])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4e866-3ba5-4da2-9745-b836e351cddf",
   "metadata": {},
   "source": [
    "See those edge effects? The model does not have enough spatial information on the boundaries, thus it predicts them erroneously. We normally clip the boundaries by a given stride when assessing accuracy in small tiles. We stitch them together when doing the prediction of larger scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e0534-3b93-482f-b64f-5dd53e365953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel",
   "language": "python",
   "name": "ilab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
